La concorrenza può portare ad una serie di problematiche legate all'utilizzo di una stessa risorsa condivisa da parte di più processi. Un determinato susseguirsi di eventi può causare condizioni critiche. La programmazione concorrente sfrutta alcuni principi per fronteggiare e risolvere questo tipo di problematiche. Corse critiche (Race conditions): In alcuni sistemi può accadere che i processi in esecuzione condividano una risorsa comune di qualsiasi natura (sia essa un'area di memoria condivisa o una periferica). In particolare se si verifica che il risultato finale dell'esecuzione di più processi dipende dall'ordine in cui essi vengono eseguiti, questa è una condizione di corsa critica (race condition). Il risultato dell'esecuzione nel caso di corse critiche è assolutamente impredicibile. Il problema delle "corse critiche" può essere evitato impedendo che più di un processo per volta acceda a risorse condivise. Con la mutua esclusione si evita che più processi che contendono una risorsa riescano ad accedervi contemporaneamente. Stallo (Deadlock): Quando ad un processo viene garantito l'accesso esclusivo (ad esempio tramite una mutua esclusione) ad una risorsa, possono crearsi situazioni di stallo. Formalmente un insieme di processi è in stallo (deadlock) quando ogni processo dell'insieme attende un evento che può avvenire soltanto tramite un altro processo dell'insieme. Essendo tutti i processi in attesa, nessuno potrà mai creare l'evento di sblocco protraendo l'attesa all'infinito. Le tecniche per individuare situazioni di stallo prevedono l'analisi di grafi delle risorse allocate oppure mediante la creazione di cosiddette "matrici di allocazione". La risoluzione degli stalli può essere affrontata in vari modi. Concettualmente si possono suddividere in: Risoluzione mediante pre-rilascio: viene scelto un processo che detiene una risorsa dall'insieme dei processi in stallo e viene tolto l'accesso esclusivo (prerilascio o preemption) ad una risorsa condivisa (causa di stallo). L'operazione è talvolta difficile, talvolta impossibile e dipende dal tipo di risorsa che il processo stava bloccando. Risoluzione mediante punto di controllo: vengono creati dei registri (checkpoint) che descrivono lo stato di utilizzo delle risorse condivise. Quando viene rilevato uno stallo si effettua un "ritorno" (rollback to checkpoint) alle condizioni precedenti. Anche questa tecnica è di difficile o addirittura impossibile realizzazione poiché il ritorno potrebbe causare perdita o inconsistenza di dati. Risoluzione mediante eliminazione: viene scelto un processo e viene terminato. Questa tecnica è anch'essa molto complessa e richiede di fare stime e assunzioni sul tipo di processo da eliminare. Inoltre non è garantita l'uscita dalla condizione di stallo per cui potrebbe essere necessario terminare altri processi, situazione che complica ulteriormente la problematica. È anche possibile effettuare delle stime sulle risorse che verranno impegnate da un processo. Grazie a tali stime, esistono sistemi in cui invece di risolvere le situazioni di stallo risulta più semplice evitarle a priori. Tutte le tecniche prevedono la costruzione di matrici che tengono traccia dell'utilizzo delle risorse (matrici di traiettoria di risorse) o si basano su algoritmi noti come l'algoritmo del banchiere. Starvation: Letteralmente inedia, è un problema in stretta relazione con lo stallo. Quando le politiche di assegnazione delle risorse condivise favoriscono un processo rispetto ad un altro, il processo a cui vengono assegnate in minor misura soffre di starvation. Esso è infatti bloccato e non può proseguire sebbene non si trovi in una condizione di stallo. Nei sistemi in cui si accede a risorse condivise è sempre necessario stabilire una politica per le priorità e l'ordine con cui esse vengono ripartite. Sebbene queste politiche possano risultare quanto più eque, esse possono portare a condizioni di starvation.

La concorrenza può portare ad una serie di problematiche legate all'utili
zzo di una stessa risorsa condivisa da parte di più processi. Un determin
ato susseguirsi di eventi può causare condizioni critiche. La programmazi
one concorrente sfrutta alcuni principi per fronteggiare e risolvere ques
to tipo di problematiche. Corse critiche (Race conditions): In alcuni sis
temi può accadere che i processi in esecuzione condividano una risorsa co
mune di qualsiasi natura (sia essa un'area di memoria condivisa o una per
iferica). In particolare se si verifica che il risultato finale dell'esec
uzione di più processi dipende dall'ordine in cui essi vengono eseguiti, 
questa è una condizione di corsa critica (race condition). Il risultato d
ell'esecuzione nel caso di corse critiche è assolutamente impredicibile. 
Il problema delle "corse critiche" può essere evitato impedendo che più d
i un processo per volta acceda a risorse condivise. Con la mutua esclusio
ne si evita che più processi che contendono una risorsa riescano ad acced
ervi contemporaneamente. Stallo (Deadlock): Quando ad un processo viene g
arantito l'accesso esclusivo (ad esempio tramite una mutua esclusione) ad
 una risorsa, possono crearsi situazioni di stallo. Formalmente un insiem
e di processi è in stallo (deadlock) quando ogni processo dell'insieme at
tende un evento che può avvenire soltanto tramite un altro processo dell'
insieme. Essendo tutti i processi in attesa, nessuno potrà mai creare l'e
vento di sblocco protraendo l'attesa all'infinito. Le tecniche per indivi
duare situazioni di stallo prevedono l'analisi di grafi delle risorse all
ocate oppure mediante la creazione di cosiddette "matrici di allocazione"
. La risoluzione degli stalli può essere affrontata in vari modi. Concett
ualmente si possono suddividere in: Risoluzione mediante pre-rilascio: vi
ene scelto un processo che detiene una risorsa dall'insieme dei processi 
in stallo e viene tolto l'accesso esclusivo (prerilascio o preemption) ad
 una risorsa condivisa (causa di stallo). L'operazione è talvolta diffici
le, talvolta impossibile e dipende dal tipo di risorsa che il processo st
ava bloccando. Risoluzione mediante punto di controllo: vengono creati de
i registri (checkpoint) che descrivono lo stato di utilizzo delle risorse
 condivise. Quando viene rilevato uno stallo si effettua un "ritorno" (ro
llback to checkpoint) alle condizioni precedenti. Anche questa tecnica è 
di difficile o addirittura impossibile realizzazione poiché il ritorno po
trebbe causare perdita o inconsistenza di dati. Risoluzione mediante elim
inazione: viene scelto un processo e viene terminato. Questa tecnica è an
ch'essa molto complessa e richiede di fare stime e assunzioni sul tipo di
 processo da eliminare. Inoltre non è garantita l'uscita dalla condizione
 di stallo per cui potrebbe essere necessario terminare altri processi, s
ituazione che complica ulteriormente la problematica. È anche possibile e
ffettuare delle stime sulle risorse che verranno impegnate da un processo
. Grazie a tali stime, esistono sistemi in cui invece di risolvere le sit
uazioni di stallo risulta più semplice evitarle a priori. Tutte le tecnic
he prevedono la costruzione di matrici che tengono traccia dell'utilizzo 
delle risorse (matrici di traiettoria di risorse) o si basano su algoritm
i noti come l'algoritmo del banchiere. Starvation: Letteralmente inedia, 
è un problema in stretta relazione con lo stallo. Quando le politiche di 
assegnazione delle risorse condivise favoriscono un processo rispetto ad 
un altro, il processo a cui vengono assegnate in minor misura soffre di s
tarvation. Esso è infatti bloccato e non può proseguire sebbene non si tr
ovi in una condizione di stallo. Nei sistemi in cui si accede a risorse c
ondivise è sempre necessario stabilire una politica per le priorità e l'o
rdine con cui esse vengono ripartite. Sebbene queste politiche possano ri
sultare quanto più eque, esse possono portare a condizioni di starvation.

54 73